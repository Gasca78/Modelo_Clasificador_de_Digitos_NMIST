# üß† Clasificador de D√≠gitos MNIST con PyTorch

![Python](https://img.shields.io/badge/Python-3.9-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Torchvision](https://img.shields.io/badge/Torchvision-E98E2E?style=for-the-badge&logo=pytorch&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

---

### üìñ Resumen del Proyecto

Este proyecto implementa un clasificador de im√°genes para el ic√≥nico dataset **MNIST** de d√≠gitos manuscritos. Utilizando **PyTorch**, se construye y entrena una Red Neuronal Densa (DNN) desde cero para reconocer y clasificar correctamente los d√≠gitos del 0 al 9.

Adem√°s de la clasificaci√≥n, el proyecto incluye un an√°lisis de **interpretabilidad del modelo**, donde se visualiza un mapa de calor que muestra qu√© p√≠xeles de la imagen de entrada son los m√°s influyentes para la toma de decisiones del modelo.

---

### üéØ Objetivo

El objetivo principal es construir un modelo de Deep Learning capaz de alcanzar una alta precisi√≥n en la clasificaci√≥n de los d√≠gitos del dataset MNIST, demostrando un entendimiento s√≥lido de los fundamentos de las redes neuronales para la clasificaci√≥n de im√°genes.

---

### üìä Dataset

Se utiliza el dataset **MNIST**, cargado directamente a trav√©s de la librer√≠a `torchvision`. Este conjunto de datos consta de:
* **60,000 im√°genes de entrenamiento** y **10,000 im√°genes de prueba**.
* Cada imagen es una representaci√≥n en escala de grises de 28x28 p√≠xeles de un d√≠gito manuscrito.

---

### üõ†Ô∏è Metodolog√≠a

1.  **Carga y Preparaci√≥n de Datos:**
    * Se utiliza `torchvision.datasets.MNIST` para descargar y cargar los datos.
    * Las im√°genes de 28x28 p√≠xeles se "aplanan" en vectores de 784 p√≠xeles para que sirvan como entrada a la red neuronal densa.

2.  **Arquitectura del Modelo:**
    * Se define una **Red Neuronal Densa (DNN)** con una capa de entrada de 784 neuronas, una capa oculta de 20 neuronas con activaci√≥n ReLU, y una capa de salida de 10 neuronas (una para cada d√≠gito).

3.  **Entrenamiento:**
    * Se utiliza la funci√≥n de p√©rdida `CrossEntropyLoss`, que es el est√°ndar para problemas de clasificaci√≥n multiclase.
    * Se emplea el optimizador `Adam` para ajustar los pesos del modelo durante 5,000 iteraciones.

4.  **An√°lisis de Importancia de P√≠xeles:**
    * Una vez entrenado el modelo, se extraen los pesos de la primera capa oculta.
    * Se calcula el promedio del valor absoluto de los pesos conectados a cada p√≠xel de entrada.
    * El resultado se visualiza como un **mapa de calor de 28x28**, que resalta las √°reas de la imagen que el modelo considera m√°s importantes para clasificar los d√≠gitos.

---

### üìà Resultados

El modelo entrenado alcanz√≥ un rendimiento s√≥lido:

* **Precisi√≥n en el conjunto de entrenamiento:** **95.63%**
* **Precisi√≥n en el conjunto de prueba:** **92.24%**

El mapa de calor de importancia de p√≠xeles revela que el modelo aprendi√≥ a enfocarse en el √°rea central de la imagen, donde se dibujan los d√≠gitos, y a ignorar los bordes, que generalmente est√°n vac√≠os.

---

### üöÄ C√≥mo Ejecutar este Proyecto

1.  Clonar el repositorio.
2.  Abrir el notebook `.ipynb` en un entorno como Google Colab o Jupyter Notebook.
3.  Ejecutar las celdas en orden. El dataset MNIST se descargar√° autom√°ticamente a trav√©s de `torchvision` en la primera ejecuci√≥n.
